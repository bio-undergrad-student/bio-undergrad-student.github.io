<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Tutorials on Image Analysis Algorithms</title>
    <link>/posts/</link>
    <description>Tutorials on Image Analysis Algorithms (Posts)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    

    
    
    <atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>1. Algorithms Primer Part 1 :abacus:</title>
      <link>/posts/algorithms1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/algorithms1/</guid>
      <description>&lt;p&gt;In this tutorial we will go over some basic algorithms concepts along with some examples and exercises.&lt;/p&gt;
&lt;h2 id=&#34;what-are-algorithms&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#what-are-algorithms&#34;&gt;
        #
    &lt;/a&gt;
    What are algorithms?
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;An algorithm is essentially a set of instructions. Think about writing a bulleted list of everything you’d want a robot to do in sequential order. Take a look at the following example where we come up with a simple algorithm to retrieve a strawberry from a refrigerator.&lt;/p&gt;
&lt;p&gt;Move forward 3 steps → Move left 2 steps → Raise arm → Grab refrigerator door → Open refrigerator → Find strawberry → Grab strawberry → Put strawberry in basket → Close refrigerator door → Turn around → Move forward 2 steps → Move right 3 steps → Drop basket on target&lt;/p&gt;
&lt;p&gt;This is basically just a sequence of steps that the robot must follow, this is a very simple example of an algorithm. In practice we would have to translate each step into a code version, but that is secondary to designing algorithms.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/robot.jpg&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;basic-coding-refresher&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#basic-coding-refresher&#34;&gt;
        ##
    &lt;/a&gt;
    Basic Coding Refresher
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;Knowing basic coding operations is crucial in developing algorithms. The two main control structures we are concerned with are the if-else statement and for loop. These are the most frequently used in writing algorithms and it is important to understand exactly how they work.&lt;/p&gt;
&lt;p&gt;In the example of a real strawberry retrieving robot we have to specify exactly what we want from it using a programming language. Below is an example of what an instruction might look like in Python.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if is_in_refrigerator(strawberry) == true
    Robot.retrieve_item(strawberry)
else
    Robot.return()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now if we wanted to use a for loop to retrieve multiple strawberries then we could use the following instruction &amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for i in range(10)
    if is_in_refrigerator(strawberry) == true
        Robot.retrieve_item(strawberry)
    else
        Robot.return()
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;what-makes-a-good-algorithm&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#what-makes-a-good-algorithm&#34;&gt;
        ##
    &lt;/a&gt;
    What makes a good algorithm?
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;Whether an algorithm is considered good depends on the many qualities of that algorithm. Two of the most important qualities of an algorithm are space and time.&lt;/p&gt;
&lt;p&gt;Now what does space and time mean in the context of something running on a computer? Space refers to the amount of information that an algorithm saves during runtime. An example of space would be if we were required to store location information in our strawberry retrieval algorithm in order to backtrack and get back to our starting point. For systems such as robots that run on tight memory limitations, being mindful of memory usage is very important.&lt;/p&gt;
&lt;p&gt;Time is often thought to be the most important factor when designing an algorithm. Here time refers not to the literal wall clock time your algorithm runs in but rather the asymptotic complexity. The best way to think of time complexity is to think of your algorithm as a function of the input size. So ask yourself &amp;ldquo;as my input size increases how much additional work do I have to do?&amp;rdquo; As an example lets think about the time complexity of the code below using a for loop&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;n = len(input)
for i in range(n)
     print(&amp;quot;Hello World!&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we have a for loop that runs in time proportional to the size of the input. In this case we say that the algorithm runs in $O(n)$ or &amp;ldquo;big O of n time&amp;rdquo;. This means the algorithm runtime grows in a linear fashion with respect to the input size much like the function $f(x) = x$. Below is a visual of the different common time complexities you may encounter when developing algorithms.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/bigo.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;basics&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#basics&#34;&gt;
        #
    &lt;/a&gt;
    Basics
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;Most of the algorithms we first learn about in computer science courses are very basic, we are tasked with completing tasks such as ordering a list of numbers or finding the maximum element in that list. In this section of the algorithms primer you will learn a bit about these two tasks in an interactive way. The two tasks are formally known as searching and sorting tasks and by the end of this section you will implement your own list searching and sorting algorithms.&lt;/p&gt;
&lt;h3 id=&#34;data-structures&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#data-structures&#34;&gt;
        ##
    &lt;/a&gt;
    Data Structures
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;Before starting on algorithm development, it is important to be aware of various data structures. In this tutorial we are only concerned with the list or array, but there exists a wide variety of data structures each of which have their purpose and can help algorithms run faster. So lets learn a little more about our friend the list/array, as with most data structures we associate a time complexity to the operations we can perform on the structure. Here we have three distinct tasks i.e. insertion, deletion, and query.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Insertion&lt;/strong&gt; of an element into a list in $O(1)$ or &amp;ldquo;constant&amp;rdquo; time because we simply add it to the end of the list effortlessly.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Deletion&lt;/strong&gt; of an element in a list can get a little complicated. If the element we want to delete just happens to be the last element in the list then we can achieve a deletion in $O(1)$. However, suppose the element we want to delete just happens to be the first in the list, now we&amp;rsquo;d have to delete the first element then shift the remaining elements forward by one. Here we now have a $O(n)$ operation since we are required to work with each element at one time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Query&lt;/strong&gt; or searching of a particular element in a list is similar to the example of deletion. For querying we have to search through our various elements and check for a match, this mean manually checking each and every element at least once. So the time complexity of querying an element in a list is $O(n)$. Later in this tutorial you will have the chance to implement an algorithm to perform this query operation.&lt;/p&gt;
&lt;h3 id=&#34;searchingquerying-tasks&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#searchingquerying-tasks&#34;&gt;
        ##
    &lt;/a&gt;
    Searching/Querying Tasks
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;A searching task is exactly what it sounds like, generally our goal is to search for a particular element within a data structure which is what holds our data. In this part of the tutorial our main objective will be to find a particular number within a list. More formally this problem is defined as searching for a particular integer value within an array. Take the list below as an example&amp;hellip;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/array.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;It is simple enough for us to determine if the number 5 is in the list, we can just look at it, for the computer it is a bit more complicated than that, we have to explicitly tell it how to know if a number is present. This is something we have to get used to.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt; What is the simplest way to have the computer tell us if a known number is present in a list?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We have an array named myList, and we can query the fourth element in the list as follows&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;myNumber = myList[3]
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt; Write some code to tell us if the 6th element in the list is equal to 3.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;How can we apply a conditional statement to all elements in an array of unknown length? Regardless of what the size of an array is at runtime we can retrieve that number using the length function i.e. &lt;code&gt;len(myList)&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 3&lt;/strong&gt; Write some code to check all elements of the list to see if they are equal to 7.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That’s cool, but now imagine that we are given a stream of queries and we don’t know what the numbers are, how can we check if all of these numbers are present in our array? Suppose we have two arrays now, we have myList and we have a new array named queries. This is a list containing random numbers, our goal is to for each number in queries, check if it is present in myList.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 4&lt;/strong&gt; Now lets generalize, write an algorithm to search the myList array for all of the numbers in the queries array.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Congratulations, you just wrote an algorithm to query lists of integers!&lt;/p&gt;
&lt;h3 id=&#34;sorting-tasks&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#sorting-tasks&#34;&gt;
        ##
    &lt;/a&gt;
    Sorting Tasks
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;Now lets try a different, and more challenging, example, this time we want to take a list of numbers and sort them in increasing order. To write an algorithm for this problem we will take the same approach as we did for searching and try to solve simpler instances of the problem and then generalize.&lt;/p&gt;
&lt;p&gt;Lets start with an example of a list of size 2. What is the simplest way to sort the list below of size 2? Don’t think about the code for now just think about what the flowchart would look like.&lt;/p&gt;
&lt;p&gt;Assume you have access to a swap function that work as in the example below…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;myList = [1,2,3,4,5]

swap(myList[0],myList[1])

print(myList) # Output: [2,1,3,4,5]
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 5&lt;/strong&gt; Implement some code to sort a list of numbers of size 2.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if myList[0] &amp;gt; myList[1]
        swap(myList[0], myList[1])
        return myList
else
        return myList
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This code essentially asks one fundamental question i.e. is the first element smaller than the second? Now we are going to make a intellectual jump in order to generalize this problem, think about the following idea to sort a list of arbitrary size.&lt;/p&gt;
&lt;p&gt;What process would you use in order to solve this problem on a list of size 3 like the one below?&lt;/p&gt;
&lt;p&gt;What if we ask this same fundamental question repeatedly on sublists of a larger list. Take the list below as an example, first we will ask the same question from earlier “is the first element smaller than all subsequent numbers” the only difference is that we are now talking about all the numbers that follow. Next we will ask the same question but starting at the second index, ignoring all prior elements. We will repeat this process until we are left with only the last two elements, before we know it our list will be in increasing order.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 6&lt;/strong&gt; Write some code that will sort an array of integers using the idea above.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for i in range(len(myList))
    for j in range(i, len(myList))
        if(myList[j] &amp;lt; myList[i])
            swap(myList[i], myList[j])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Remark 1&lt;/strong&gt; Can we prove that this will always work? In algorithms we must prove that an algorithm will return the correct output and run under specific time bounds. This is beyond the scope of this tutorial but I will provide an example below for those who are interested.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Proof&lt;/strong&gt; This proof will be pretty informal but for the purpose of this tutorial it really doesn&amp;rsquo;t matter. Selection sort works because, in each step, you find the smallest thing left and put it where it belongs. By the time you’ve gone through all the steps, everything is in the right place.&lt;/p&gt;
&lt;p&gt;Think of organizing a deck of cards: you look for the smallest card, put it at the front, then look for the next smallest card, and so on. Since you&amp;rsquo;re always finding the smallest and putting it where it should go, by the end, everything is perfectly sorted!&lt;/p&gt;
&lt;p&gt;In all algorithms courses and in research we always look for two fundamental pieces when an algorithm is presented, a proof of its time complexity and a proof of correctness.&lt;/p&gt;
&lt;h3 id=&#34;on-generalization&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#on-generalization&#34;&gt;
        ##
    &lt;/a&gt;
    On generalization
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;Notice in the examples above, in searching and sorting we were able to take a simple task such as searching for the number 15 or determining the order of two integers and then generalize to arbitrary sets of data. Ultimately this is exactly what we do in order to solve the hardest problems in computer science. Think back to the robot problem from the beginning of this tutorial, we wanted to address the task of retrieving a strawberry from a refrigerator. Now imagine we wanted to generalize this algorithm to work on arbitrary item, not necessarily a strawberry and also imagine we wanted to generalize the location of the item. What you are now thinking would be an example of a more sophisticated artificial intelligence algorithm. In many cases we can generalize a problem enough and reframe it to solve a seemingly unrelated problem. For example what if instead of a strawberry in a kitchen setting we were in a torn down town after a natural disaster and the objective is to find survivors. This is a much more complicated task as the size of the space we are searching has become exponentially larger and the stakes are higher as we are searching for human life.&lt;/p&gt;
&lt;h2 id=&#34;conclusions-and-additional-resources&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#conclusions-and-additional-resources&#34;&gt;
        #
    &lt;/a&gt;
    Conclusions and additional resources
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;This concludes the first part of this algorithms primer tutorial, in the next tutorial you will learn more about general algorithm development frameworks that can be useful during your journey. Below I have also attached an amazing Computerphile video covering sorting algorithms and time complexity topics, I hope you enjoy! See you next time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Readings&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.math.umd.edu/~immortal/CMSC351/notes/algorithmtimecomplexity.pdf&#34;&gt;Time Complexity Notes: Justin Wyss-Gallifent&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;strong&gt;Videos&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/kgBjXUE_Nwc&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;!-- raw HTML omitted --&gt;</description>
    </item>
    
    <item>
      <title>2. Algorithms Primer Part 2 :gear:</title>
      <link>/posts/algorithms2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/algorithms2/</guid>
      <description>&lt;p&gt;In this tutorial we will go over some more general frameworks that are used in the algorithm development process, along the way we will cover some examples and exercises.&lt;/p&gt;
&lt;h2 id=&#34;general-frameworks&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#general-frameworks&#34;&gt;
        #
    &lt;/a&gt;
    General Frameworks
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;It is often the case that beginners struggle with algorithms puzzles/problems such as those found on popular websites like LeetCode. The struggle primarily comes from a lack of a developed algorithms toolbox, the truth is that inventing a complicated algorithm just to solve a puzzle is not ideal. As we expand our knowledge of algorithmic techniques, data structures, and types of problems we find that some of these puzzles are trivial once you know the technique it is testing. Therefore your goal should be to learn as many techniques as possible to have the easiest time solving an algorithms problem.  In this tutorial we will cover two of the most popular techniques we see in algorithms development along with some examples and exercises. The two techniques being covered are divide and conquer and greedy, these can be often be applied to a wide range of problems regardless of domain.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Like all tutorials we will start with an example that incorporates these techniques. For the sake of this example suppose you are a working as part of a team of marmots whose diets are made up entirely of strawberries, they are also having a hard time working out the logistics of their food supply. This means that they are distributing strawberries to marmots at random, the problem with this approach is that small marmots are getting large strawberries (surplus) and large marmots are getting small strawberries (shortage). Thus, small marmots are contributing to a large amount of food waste and large marmots are going hungry, how can we use algorithms to solve this problem quickly as the marmots are very hungry?&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;http://localhost:1313/images/marmot.jpg&#34;
         alt=&#34;Example Image&#34; width=&#34;300px&#34;/&gt;
&lt;/figure&gt;

&lt;h3 id=&#34;divide-and-conquer&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#divide-and-conquer&#34;&gt;
        ##
    &lt;/a&gt;
    Divide and Conquer
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;Divide and conquer is a problem solving approach/framework which is a bit self explanatory. The technique works by splitting our input in smaller chunks, solving the smaller instances of the problem and then combine the results to solve the full problem. Now this approach cannot be applied to every problem, there are some limitations such as independence that we must be cautious of. Independence in this context refers to the idea that each one of our sub-problems, after splitting the input data, has no relation at all to the other sub-problems. This may become a little more clear once we go over the following example for sorting a list of integers. Suppose we are given the list below…&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/lilarray.jpg&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;p&gt;We want to sort this list under a time constraint but the size of the input array is far too large to be done using our sorting algorithm we learned in part 1, how do we address this problem? Let’s apply the divide and conquer problem solving approach to this!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt; Come up with three ideas of how we can split our input array in order to solve it more efficiently.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Great! Now the splitting of the array we are interested in is depicted below, here we do the splitting in half each time until we can’t split any further.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/dand1.jpg&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;p&gt;At this point we have a bunch of arrays of size 1 that are each in sorted order, why? Any list of one element is automatically in sorted order because there is only one element. Now how will this help us sort the entire list, we haven’t done any type of sorting so far? The trick comes in when we combine the sub-lists, we will sort them as we reconstruct a list of the original size. Take a look at the example below which completes one step of this reconstruction&amp;hellip;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/dand2.jpg&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here we take all of our lists of size 1 and construct $\frac{n}{2}$ lists of size 2 which are in sorted order. The sorting happens when we insert our elements into the list of size 2, the smallest element comes first and then the larger element. The algorithm will continue this procedure until we end up with a single list of size $n$, we call this algorithm Merge Sort. The algorithm makes use of a recursive function, meaning a function that calls itself over and over until some base case is reached, in this case we continue calling the &lt;code&gt;MERGE-SORT&lt;/code&gt; function as long as our lists have size greater than 1. Below is some code for the Merge Sort algorithm and the complete reconstruction of the list.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;MERGE-SORT(array, left, right):
    if left &amp;lt; right:
        mid = (left + right) / 2

        # Recursively sort the two halves
        MERGE-SORT(array, left, mid)
        MERGE-SORT(array, mid + 1, right)

        # Merge the sorted halves
        MERGE(array, left, mid, right)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/dand3.jpg&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;p&gt;By using the divide and conquer approach we have now solved the sorting problem much faster than we could before, lets analyze to confirm.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Splitting Operation:&lt;/strong&gt; The big question is how do we represent this splitting and combining operation, clearly this doesn’t touch each element once so it’s not $O(n)$ nor is it doing constant $O(1)$ work, it’s something in between. We call this behavior $O(log(n))$, why? First we must understand what it is that the log function does, think about the following equation&amp;hellip;&lt;/p&gt;
&lt;p&gt;$$log_2(n) = c \iff 2^c =n$$&lt;/p&gt;
&lt;p&gt;When we take the log base 2 of some number what we get in return is the exact exponent of a base 2 exponential required to get of that “some number”. It takes a while to grasp but another way to think of it in terms of a list of size n, the log base 2 of n is equal to the number of times we have to split this list and it’s sub-lists in two before we get lists of size 1. This is the exact operation we are doing in Merge Sort, hence the reason why this splitting operation runs in $O(log(n))$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Merging Operation:&lt;/strong&gt; Now you might be asking if the splitting operation is $O(log(n))$ then combining is also $O(log(n))$ right? So why is the total time complexity of Merge Sort $O(n log(n))$? This is because the combining operation is not $O(log(n))$, lets really think about what is happening here, when we merge two lists we have to ask the question “which of these elements is the smallest?” And we ask this same question for all other sub-lists, in the worst case scenario we’d have to look through all $n$ of our elements one time just to make sure we have the smallest element each time. Furthermore, we are doing these checks totaling to $n$ comparison at each step of the combination process so that is $log(n)$ steps times $n$ checks $= nlog(n) \in O(n log(n))$. This completes the time analysis of Merge Sort.&lt;/p&gt;
&lt;p&gt;So as we have seen, divide and conquer approach can be very useful in cases such as sorting where sub problems are completely independent of each other. Next we will take a look at another approach which we will use alongside divide and conquer in order to solve the marmot-strawberry crisis.&lt;/p&gt;
&lt;h3 id=&#34;greedy-algorithms&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#greedy-algorithms&#34;&gt;
        ##
    &lt;/a&gt;
    Greedy Algorithms
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;The greedy approach to algorithm development is where we make a greedy decision in order to accomplish some task. In this context greedy refers to always taking as much as possible of some quantity. As an example we will go through the well known coin change problem. This is a problem where we are given a set of coin denominations (e.g. 1 cent, 5 cent, 10 cent) and we are asked what is the minimum number of coins required to make a certain amount of change. For example, 35 cents change can be made from 3x10 cent coins and 1x5 cent coin. In this case the greedy approach can be used to find the minimum number of coins required to make change for 35 cents. We simply take as many 10 cent coins as possible followed up by as many 5 cent coins as possible, this gives us 35 cents using 4 coins, any other combination would use more coins. As we can see we make a greedy decision at every step, always take as much as we can.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/coins.jpg&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now the problem with the greedy approach is that it doesn’t always work&amp;hellip;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt; Can you find a counterexample for the greedy algorithm for the coin change problem?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Possible Solution&lt;/strong&gt; $denominations = {1,2,4,5}$ make change for 8 cents $5+1+1+1$ vs $4+4$&lt;/p&gt;
&lt;p&gt;Here the problem is that it is more efficient to make change using the 4 cent coins as opposed to using the 5 cent coin.&lt;/p&gt;
&lt;p&gt;Below I provide some example code for the greedy coin change problem&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GREEDY-COIN-CHANGE(coins, amount):
    #coins is array of coin denominations
    
    sort(coins) # in decreasing order

    result = 0

    # Iterate over each coin
    for coin in coins:
        if amount == 0:
            break
        
        # Use as many of this coin as possible
        count = amount / coin
        result = result + count

        # Reduce the remaining amount
        amount = amount - count * coin

    # If amount is not 0, the greedy approach may not work for this set of coins
    
    if amount &amp;gt; 0:
        return -1  # Indicates it&#39;s not possible to make the exact amount

    return result
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the greedy approach is a very general framework, it can be applied in many different settings so we always have to keep an eye out. Next we will get a chance to apply this framework alongside the greedy approach to solve the problem from the introduction.&lt;/p&gt;
&lt;h3 id=&#34;addressing-food-insecurity-in-marmot-communities&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#addressing-food-insecurity-in-marmot-communities&#34;&gt;
        ##
    &lt;/a&gt;
    Addressing food insecurity in marmot communities
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;Now that we are equipped with more algorithmic tools to solve problems we are ready to solve the marmot-strawberry problem. Recall the problem statement; given that the community of marmots consists of n members each with an associated weight and we want to distribute n strawberries each with an associated size, find the best marmot-strawberry matching. Target time complexity: $O(nlog(n))$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 3&lt;/strong&gt; Think about a potential solution to this problem, think about the algorithms and techniques we have learned so far in this chapter.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Hint&lt;/strong&gt; Remember our goal here is to match big strawberries with big marmots and small strawberries with small marmots. Which tool can help us order objects?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 4&lt;/strong&gt; Given the two ordered lists of marmots and strawberries, how can we optimally choose marmot-strawberry assignments?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The idea here is to create arrays with the weights and sizes of both the marmots and the strawberries and then sort them in descending order. Since we know that the number of marmots and strawberries are the same then we know each marmot will get exactly one strawberry. Thus we can simply assign strawberries to marmots greedily, let the largest marmot take the largest strawberry then remove the pair from the list, continue this procedure until the lists are empty. This gives us a very simply greedy strawberry allocation algorithm, we can make things a little harder by allowing there to be more strawberries than marmots and thinking about how we would distribute the strawberries then.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 5&lt;/strong&gt; Implement an algorithm to solve the marmot-strawberry problem&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;conclusions&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#conclusions&#34;&gt;
        ##
    &lt;/a&gt;
    Conclusions
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;In future tutorials you will have the opportunity to develop your algorithmic thinking skills through applications in the biological sciences. Specifically we will be dealing with imaging data. There are countless procedures/assays that produce images, learning how to write the programs that analyze this type of data is crucial in modern lab settings. Below I have provided some additional readings on greedy algorithms and a video for divide and conquer. See you next time!&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;strong&gt;Readings&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.math.umd.edu/~immortal/CMSC351/notes/mergesort.pdf&#34;&gt;Merge Sort: Justin Wyss-Gallifent&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.math.umd.edu/~immortal/CMSC351/notes/coinchanging.pdf&#34;&gt;Coin Change: Justin Wyss-Gallifent&lt;/a&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;strong&gt;Videos&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/ib4BHvr5-Ao&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;!-- raw HTML omitted --&gt;</description>
    </item>
    
    <item>
      <title>3. Analyzing Images With Fiji :desert_island:</title>
      <link>/posts/fiji/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/fiji/</guid>
      <description>&lt;p&gt;In this tutorial we will go over the basic analysis functionalities of the image analysis software Fiji.&lt;/p&gt;
&lt;p&gt;This the following couple of posts will be a series of tutorials on existing software for analyzing cellular imaging data. We will provide an essential quick start guide and encourage everyone to spend time messing around with these tools and some provided datasets to familiarize themselves with them. There will be 3/4 tutorials for this series where we will cover software for image analysis for small and large scale experiments, after we will dive into more experimental deep learning methods and introduction to cellular imaging data integration and batch correction.&lt;/p&gt;
&lt;h2 id=&#34;background&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#background&#34;&gt;
        #
    &lt;/a&gt;
    Background
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/island.jpg&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;p&gt;Did you know that the soft coral capital of the world, Fiji, is made 90% of water and has over 300 tropical islands! Unfortunately we will not be doing image analysis on the islands of Fiji. In this tutorial we will go over the image processing software Fiji. “Fiji is just ImageJ” is an open-source image processing software and extension of the original ImageJ developed at the National Institutes of Health (NIH). Fiji is used extensively in image analysis for microscopy images in 2D and 3D and is used in labs across the world to analyze phenotypic changes in cells at scale. Today you will have the opportunity to install this software on your computer and run through some basic analyses using some of the preset datasets within Fiji. Additionally, we will provide a mini-project in the next post which will help you familiarize yourself more with the ImageJ interface and identify potential applications in a field of your interest.&lt;/p&gt;
&lt;h2 id=&#34;installation&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#installation&#34;&gt;
        #
    &lt;/a&gt;
    Installation
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;First you will go to the ImageJ documentation website and navigate &lt;code&gt;Explore&lt;/code&gt; → &lt;code&gt;Software&lt;/code&gt; → &lt;code&gt;Fiji&lt;/code&gt;. Or just follow this link: &lt;a href=&#34;https://imagej.net/software/fiji/&#34;&gt;https://imagej.net/software/fiji/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Once here you will choose the appropriate download depending on your operating system (OS). This tutorial will assume the usage of window OS but the process should be very similar for Mac devices.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/downloads.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;Create a new folder on your desktop to store Fiji and all of your work for this class. The file you have just downloaded will come in a .zip file, extract the files and you can delete the .zip afterwards. Then navigate into the Fiji.app folder and open the ImageJ-win64 (if you’re on windows) application. You will be greeted with some additional documentation windows and a prompt to update the client, please update your ImageJ to the latest version. If you did not receive an update message navigate to &lt;code&gt;Help&lt;/code&gt; →  &lt;code&gt;Update&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Navigate to the ImageJ Updater (&lt;code&gt;Help&lt;/code&gt; →  &lt;code&gt;Update&lt;/code&gt;) as just specified and hit “Manage Update Sites” scroll and find the plugin called “Bio-Formats”, check the box, apply update, and restart ImageJ. Bio-Formats is a plugin which will allow us to import images of various file formats outputted by microscopes. Some common examples of these file types you may come across include TIFF/OME-TIFF, CZI, ND2, etc. Check the Bio-Formats documentation for a complete list, these are just some of the most popular.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/bioformats.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;This completes the software setup section of this tutorial, now we can start working with some data.&lt;/p&gt;
&lt;h2 id=&#34;some-basics&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#some-basics&#34;&gt;
        #
    &lt;/a&gt;
    Some Basics
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;Fiji comes with many preset data samples that we can use to test out some of the features of this software (&lt;code&gt;File&lt;/code&gt; →  &lt;code&gt;Open Samples&lt;/code&gt;). By the end of this tutorial you will learn how to do some basic preprocessing and morphological analysis on cellular imaging data in Fiji.&lt;/p&gt;
&lt;p&gt;Now we will go over some of the basics about loading data into Fiji. It is important to understand how image files are loaded in and how you can manipulate these files effectively.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lookup Tables (LUT)&lt;/strong&gt; are how we will go about applying color to a given image, find the “LUT” tab on Fiji and you will see a wide selection of choices to be used in many applications. For the most part we are only interested in solid colors such as red, green, and blue. It is also possible to create a custom LUT but that is more advanced, for now just know that it is something you are able to do. The term lookup table is used here because we are looking up values within a table of values which maps one color in your original image to another color defined in the table.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/LUT.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Stacks&lt;/strong&gt; are used to retain multiple spatially or temporally related images taken by the microscope. Below are some examples of what each of these may look like using the “Mitosis {5D Stack}” sample from the default Fiji data shown below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/mitosis.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;An example of a normal stack (Z-stack) would be the MRI sample where we have the XY axes and then we can slide through the Z-axis of the MRI scan.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Composite Images&lt;/strong&gt; are mostly seen in florescence microscopy images and allows us to combine multiple color channels and view various cellular features at once. An example of this would be the “florescent cells” sample. Here we have three channels in RGB colors, the red (Texas Red X-Phalloidin) shows F-Actin, green (Goat anti-mouse IgG) shows tubulin, and blue (DAPI) shows nuclei. In practice we will name the images based on the stain and cellular feature so it’s important to know them well.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/rgbcells.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;How can we split multi-channel stack/composite images? It is often the case that we want to take a composite image and split it in order to preprocess different attributes of the image. In order to split an image click &lt;code&gt;Images&lt;/code&gt; → &lt;code&gt;Color&lt;/code&gt; → &lt;code&gt;Split Channels&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;filters&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#filters&#34;&gt;
        #
    &lt;/a&gt;
    Filters
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;In this section we will cover some basic filtering steps that can help reduce noise and obstructions in imaging data, this is typically the first step of a larger image processing pipeline.&lt;/p&gt;
&lt;p&gt;Max/Min/Median filtering is a technique where we take a patch of the image (kernel) and compute the max/min/median of every pixel color value in that patch and then replace the center value with the max/min/median value. The median filter has the effect that outlier values (very dark or light colors)  will get filtered out, this reduces noise and retains edges better than the averaging (mean) filter because we are not computing a new color value but using an existing one. We can see the difference in how edges are conserved using the boat sample with radius 10.0 Left=Median, Right=Mean.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/medianfilter.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt; Try applying median filtering with varying radius to an image of your choice&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt; Try applying other filters to an image of your choice (min, max, convolve, variance), what kind of effects do they have?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt; How do we select the radius when applying filters to images? This depends on what your objectives are and the type of image you are analyzing (feature size, noise, etc.), typically we start small and determine a radius size experimentally.&lt;/p&gt;
&lt;p&gt;Typically a pixel within an image is represented by three numerical values which tell us the ratio of red (R), green (G), and blue (B) that make up a certain color. So what exactly does it mean to take the maximum or minimum of these values? In the case of Fiji we are actually isolating each channel, applying the filter, then combining it again. Cool, right? In later tutorials we will cover more complicated filtering techniques which make use of mathematical transformations which can be used for better denoising and feature extraction.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/colors.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;segmentation&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#segmentation&#34;&gt;
        #
    &lt;/a&gt;
    Segmentation
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;We will now cover some basic image segmentation, specifically we will look at background removal using the Fiji functions as well as different types of thresholding. First you must make sure that your image is grayscale (&lt;code&gt;Image&lt;/code&gt; → &lt;code&gt;Type&lt;/code&gt; → &lt;code&gt;8-bit&lt;/code&gt;). The background subtraction function within Fiji works better if you have well defined edges in your image so it might help to play around with the brightness and contrast settings (&lt;code&gt;Image&lt;/code&gt; → &lt;code&gt;Adjust&lt;/code&gt; → &lt;code&gt;Brightness/Contrast&lt;/code&gt;) until your image’s edges look a little better. Some images already have plain backgrounds so removal is not necessary.&lt;/p&gt;
&lt;p&gt;Lets take for example the Blobs sample image. We can see that there is a textured background which can interfere with our analyses, in order to remove this we will have to use the rolling ball background subtraction algorithm. To apply this, select &lt;code&gt;Process&lt;/code&gt; → &lt;code&gt;Subtract Background&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt; Using this algorithm may cause image artifacts or unwanted effects so proceed with caution, for our case in purposes we can disregard any artifacting.&lt;/p&gt;
&lt;p&gt;After the background is removed or mitigated we can start trying to segment our features of interest using thresholding. Within Fiji we have many different options for thresholding which can be accessed through the (&lt;code&gt;Image&lt;/code&gt; → &lt;code&gt;Adjust&lt;/code&gt;) menu. For the time being we won’t concern ourselves with how thresholding works and that will be left for a more in depth future tutorial. The standard threshold option will allow you to manually analyze an intensity histogram which allows us to separate the image based on feature and background color. The problem with this approach is that it requires quite a bit of human thinking and reproducing the result might be difficult.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/manual_thresh.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;To address this problem we can use the &lt;code&gt;Auto Threshold&lt;/code&gt; option which can make this selection for us based on some algorithm. In total there are 17 of these that are available in Fiji and we have the option of running all of them at once and then choosing the best one as shown below.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/autothresh_2.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;Note that the output of the thresholding is a black and white image, this is called a binary image and each pixel is one of two color values either black or white. These binary images allow us to perform some additional modifications to our image. Take a look under (&lt;code&gt;Process&lt;/code&gt; → &lt;code&gt;Binary&lt;/code&gt;), these are options available for binary image manipulation. Erosion and dilation can be used to decrease or increase the outer layer from features in the image (black attributes). In future tutorials we will go over these manipulations in more detail. Once we have a segmentation that looks good we are ready to move onto the analysis of the features.&lt;/p&gt;
&lt;h2 id=&#34;analysis&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#analysis&#34;&gt;
        #
    &lt;/a&gt;
    Analysis
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;Once we have our binary image of our blobs we can run certain analyses on these, namely all of the options listed under (&lt;code&gt;Analyze&lt;/code&gt; → &lt;code&gt;Set Measurements&lt;/code&gt;). Within this menu you will be able to select/deselect measurements depending one what kind of analyses you’re doing.&lt;/p&gt;
&lt;p&gt;Pay close attention to the option at the bottom “Redirect to:” and recall that the image we are analyzing is binary, meaning that all intensity measurements such as min/max gray values make no sense at all. This redirect option will allow you to use the binary image as a mask and report measurements from another, non-binary, image. So this is when we will use the image of the blobs we duplicated earlier, we will use the binary segmentation image we created to measure features in our original image.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/set_measurements.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;Now that we have set our desired measurements we can select the (&lt;code&gt;Analyze&lt;/code&gt; → &lt;code&gt;Analyze Particles&lt;/code&gt;) option and run the analysis. Right before analyzing the blobs you must specify two attributes, namely the expected size range and circularity of your features. These options will allow you to filter out super small dot-like artifacts that shouldn’t be counted or non-circular objects. Under “Show:” you want to select overlay masks in order to display the results on the binary image, this doesn’t affect the analysis in any way just the way the output data is displayed.&lt;/p&gt;
&lt;p&gt;Now the output of the &lt;code&gt;Analyze Particles&lt;/code&gt; function should be a table where the rows correspond to different features in your image and columns correspond to the measurements you selected in the &lt;code&gt;Set Measurements&lt;/code&gt; settings.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/segmentation.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;A common error that arises in the analysis stage is that the image is inverted so we end up analyzing the background on accident. It can get a bit confusing especially when messing with the LUTs. It is important to note that the setting (&lt;code&gt;Edit&lt;/code&gt; → &lt;code&gt;Invert&lt;/code&gt;) is different from inverting the LUT, and this is the most common cause of error in the Analyze Particles function. Make sure that when you analyze the particles that the output table has a reasonable number of entries and that the correct areas are being overlay masked in the binary image.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/error.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;some-final-remarks&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#some-final-remarks&#34;&gt;
        #
    &lt;/a&gt;
    Some Final Remarks
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;A key feature that we haven’t mentioned in this tutorial is Fiji’s potential for analyzing 3D cell images. Fiji has many options as you may have noticed in the menus for 3D images and it is actually a similar process. There are many resources I will provide links to dealing with these types of images but for our case and purposes we are only concerned with 2D imaging so you are not required to learn the 3D image analysis.&lt;/p&gt;
&lt;p&gt;This pretty much concludes the Fiji basic analysis tutorial and there is still a lot for you to explore within Fiji. There are also a lot of features which Fiji lacks and in future tutorials we will be talking about other image analysis programs that take a different approach to solving this problem.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Looking Ahead&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the next post you will have the opportunity to do a project using Fiji to analyze cell morphology data and then using the Python Pandas package to do some post processing. This will ultimately reveal some of the pitfalls of Fiji and then we will address these with another software tool. Thanks for reading!&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Relevant Resources&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/hallvaaw/awesome-biological-image-analysis&#34;&gt;Awesome Biological Image Analysis&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>4. Project - Cell Morphology Analysis in Fiji :desert_island: &#43; Pandas :panda_face:</title>
      <link>/posts/project1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/project1/</guid>
      <description>&lt;p&gt;This project will serve as a more in-depth look into the different functions within Fiji and image processing in general as well as the Pandas data analysis framework.&lt;/p&gt;
&lt;p&gt;Preliminary Reading: &lt;a href=&#34;https://www.nature.com/articles/nprot.2016.105&#34;&gt;https://www.nature.com/articles/nprot.2016.105&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;background&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#background&#34;&gt;
        #
    &lt;/a&gt;
    Background
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;The last tutorial covered some of the basic functionalities of Fiji but not much opportunity was given to play around with the images and the different filters/adjustments. In this project you will be able to download raw experiment data provided by the JUMP-CP Consortium from a AWS s3 Bucket (Cloud Storage) and analyze that data using Fiji and Pandas in Python.&lt;/p&gt;
&lt;p&gt;The python portion of this project and any type of python programming can be done easily within your web browser (no download needed) by using Google Colab. This resource will allow you to create Jupyter Notebooks i.e. interactive environments where you can write and run code, visualize data, and document your work in one place. This is very convenient if you want to get started as quickly as possible or cannot download applications to your computer. In order to create a Google Colab notebook go to your Google Drive, hit the New (+) button, More, and then Google Colaboratory.&lt;/p&gt;
&lt;h2 id=&#34;jump-cp-data&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#jump-cp-data&#34;&gt;
        #
    &lt;/a&gt;
    JUMP-CP Data
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;The Joint Undertaking in Morphological Profiling - Cell Painting (JUMP-CP) is a consortium dedicated to analyze the cell morphology of cells with various chemical and genetic perturbations. It makes use the of the cell painting assay (from preliminary reading) for imaging [1].&lt;/p&gt;
&lt;p&gt;The easiest way to download this data is through a resource called Quilt, this is a software that takes the complicated task of managing specifically AWS cloud data and simplifies it but providing a user interface. It is important to consider that Quilt is not available for all project data, in the next tutorial we will go over some of the other approaches to downloading data from a cloud bucket.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://open.quiltdata.com/b/cellpainting-gallery/tree/&#34;&gt;Jump-CP Quilt&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Data within this repository is organized in a very specific manner, in order to understand this organization it is important to know the context. In the highest level of this bucket we see that the name is cellpainting-gallery within this directory we have 33 folders named cpg-00XX where cpg stands for cellpainting gallery. All of these folders represent some of the different contributors to this dataset, the primary dataset we are interested in is called ‘cpg0016-jump’.&lt;/p&gt;
&lt;p&gt;Some additional information about cpg0016 is that the cells we are imaging are osteosarcoma cells and this was a careful selection based on tests determining how visible phenotypic changes would be after perturbing the cells. The specific perturbations are classified into one of two categories, genetic perturbations such as CRISPR knockouts of (7,977 genes) and ORF overexpression of (15,131 unique genes), and chemical perturbations which are miscellaneous compounds/drugs (~115,795 compounds). All of this work was split amongst 12 different sources (data-generating centers) [1].&lt;/p&gt;
&lt;p&gt;Now click on the folder within Quilt for cpg0016, here you will be met with a separate folder for each of the different data-generating centers, click on source_1. Within each of these folders we can start start navigating the data, first you can select between viewing raw image data (images) or analyses/metadata (workspace) for the images. These folders are further narrowed down into different batches of experiments, the folders are labeled with the following convention ‘BatchX-YYYYMMDD’ to tell us the specific date which the data was curated.&lt;/p&gt;
&lt;p&gt;The images folder will be divided up further based on batch and then plate. We have multiple plates, in the case of source_1 these are actually 1536-Well plates, within each plate folder we have some metadata specific to the plate such as the layout and the images themselves (4 per well). There are different file structures and naming conventions for the different sources but it is always the same information.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Naming Convention&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt; r01c01f01p01-ch1sk1fk1fl1 &lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;r01:&lt;/strong&gt; Row 1 of plate&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;c01:&lt;/strong&gt; Column 1 of plate&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;f01:&lt;/strong&gt; Field of View (FOV) 1&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;p01:&lt;/strong&gt; Position 1&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ch1:&lt;/strong&gt; Channel 1&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;sk1:&lt;/strong&gt; Z slice 1&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;For batch_1 the channel mappings are as follows, these are the standard for the cell painting assay&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/cellpainting.png&#34; alt=&#34;Sunset&#34;&gt;
&lt;strong&gt;Figure courtesy of [2]&lt;/strong&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;1:&lt;/strong&gt; Endoplasmic Reticulum (ER)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2:&lt;/strong&gt; RNA&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3:&lt;/strong&gt; Mitochondria (Mito)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4:&lt;/strong&gt; DNA&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5:&lt;/strong&gt; AGP (Actin, Golgi, and Plasma)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; this mapping, the measured features are the same but the mapping can change from batch to batch. Make sure to double check the metadata file at Source → Workspace → BatchX → PlateY → load_data.csv.gz which tells us exactly what this mapping is, this information can be derived from the ‘FileName_OrigZ’ columns. For batch X, plate Y, and channel Z.&lt;/p&gt;
&lt;h2 id=&#34;pandas-dataframes&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#pandas-dataframes&#34;&gt;
        #
    &lt;/a&gt;
    Pandas Dataframes
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;In this project you will be looking at a lot of comma separated values (CSV) files and dataframes so it is important to have a solid foundation in this concepts. I recommend you watch the tutorial linked below in order to familiarize yourself with the framework. As mentioned earlier, all of this project can be done within Fiji and a Google Colab so you do not have to download anything other than the data.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/vmEHCJofslg&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;problem-statement&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#problem-statement&#34;&gt;
        #
    &lt;/a&gt;
    Problem Statement
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;In the previous tutorial you learned how to do a basic analysis in Fiji for the blob sample, today you will able to apply these learnings to real cellular imaging data. For this project we are primarily concerned with doing some morphological profiling of the nuclei of the perturbed cells at the following locations/config&amp;hellip;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Locations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1:&lt;/strong&gt; source_1: batch_1:plate_UL000109:row_1:column_26:fov_1&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2:&lt;/strong&gt; source_1: batch_2:plate_UL001671:row_5:column_23:fov_3&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3:&lt;/strong&gt; source_1: batch_3:plate_UL001785:row_11:column_41:fov_2&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4:&lt;/strong&gt; source_1: batch_4:plate_UL000097:row_24:column_26:fov_2&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5:&lt;/strong&gt; source_1: batch_5:plate_UL001773:row_4:column_30:fov_1&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6:&lt;/strong&gt; source_1: batch_6:plate_UL000579:row_31:column_40:fov_3&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Measurements&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1:&lt;/strong&gt; Area&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2:&lt;/strong&gt; Min gray value&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3:&lt;/strong&gt; Max gray value&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4:&lt;/strong&gt; Mean gray value&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5:&lt;/strong&gt; Center of mass&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6:&lt;/strong&gt; Shape descriptors&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;These different measurements will fill the columns of your particle analysis table, you will then export these tables as CSV files in order to run some further analyses. The following part of the project should be done using Pandas.&lt;/p&gt;
&lt;p&gt;In your Google Colab notebook open the six CSV files using pandas and run the following analyses.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1:&lt;/strong&gt; create a new row for the average of each measurement&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2:&lt;/strong&gt; create a new row for the average of each measurement&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3:&lt;/strong&gt; determine the average cell count from our sample&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4:&lt;/strong&gt; find the cell with maximum area&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5:&lt;/strong&gt; plot the data for the following columns for each dataframe&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6:&lt;/strong&gt; create a new dataframe of reduced size where we keep cells only if they are above the average size&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7:&lt;/strong&gt; merge all six dataframes into one dataframe with an additional column saying which batch it came from&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1] S. N. Chandrasekaran et al., “JUMP Cell Painting dataset: morphological impact of 136,000 chemical and genetic perturbations,” Mar. 2023, doi: &lt;a href=&#34;https://doi.org/10.1101/2023.03.23.534023&#34;&gt;https://doi.org/10.1101/2023.03.23.534023&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;[2] M.-A. Bray et al., “Cell Painting, a high-content image-based assay for morphological profiling using multiplexed fluorescent dyes,” Nature Protocols, vol. 11, no. 9, pp. 1757–1774, Aug. 2016, doi: &lt;a href=&#34;https://doi.org/10.1038/nprot.2016.105&#34;&gt;https://doi.org/10.1038/nprot.2016.105&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>5. Cloud Computing in the Biosciences :cloud:</title>
      <link>/posts/cloud/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/cloud/</guid>
      <description>&lt;p&gt;In this tutorial you will learn the basics of data storage and computation in the cloud.&lt;/p&gt;
&lt;p&gt;When we refer to cloud computing/storage this could mean many different things. An example that almost everyone is familiar with is Google Drive, this is an example of a cloud storage service hosted by Google, this is different from Google’s primary cloud computing service called Google Cloud Platform (GCP). Many technology companies have their own versions of cloud computing services and in this tutorial we will be focusing primarily on Amazon Web Services (AWS) but at the end of the day all of these services are very similar.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/plane.jpg&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;cloud-resources&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#cloud-resources&#34;&gt;
        #
    &lt;/a&gt;
    Cloud Resources
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;In the field of computational biology, researchers typically use their own computers to do their work, this could be a laptop, desktop, or even a high-performance computing cluster (supercomputer). As of recent there has been a push by a number of organizations to switch over to cloud resources, although this is more common in industry workplaces, you may still come across cloud computing in academic research facilities.  A prime example of this would be a resource coming out of the Broad Institute, a biomedical research facility, in collaboration with Microsoft called Terra.bio. Terra is a platform that promotes cloud computing as a way to increase collaboration through data and code sharing among biologists and computer scientists.&lt;/p&gt;
&lt;p&gt;The remainder of this tutorial will be dedicated to introducing various software development tools offered by these cloud computing resources in order to help you learn cellular imaging data analysis on the cloud, preparing you for any future career where cloud computing is a required skill.&lt;/p&gt;
&lt;p&gt;It is first important to understand how we are able to store our data on the cloud, we can show this through the popular AWS s3 bucket. s3 is known as a simple storage bucket which is used to back up data or for general storage purposes, these buckets are actually drives located in massive data centers run by Amazon. The same can be said about actual cloud computing resources such as Google Colab, the computers that allow you to run code (CPUs/GPUs) are located in some remote data center and you essentially connect to them as a virtual machine.&lt;/p&gt;
&lt;h2 id=&#34;downloadingviewing-data-from-the-cloud&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#downloadingviewing-data-from-the-cloud&#34;&gt;
        #
    &lt;/a&gt;
    Downloading/Viewing Data from the Cloud
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;Now without a specified user interface like Google Drive it is not immediately obvious how one can access cloud resources to store or download data.&lt;/p&gt;
&lt;p&gt;Recall from project 1 that we were able to download the JUMP-CP data from a resource called Quilt, this is a software that takes the complicated task of managing specifically AWS cloud data and simplifies it but providing a user interface. It is important to note that not all datasets or workplaces may subscribe to Quilt or related data management platforms, in this case you will have to access the cloud using a different method we will cover here.&lt;/p&gt;
&lt;h2 id=&#34;aws-command-line-interface-cli&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#aws-command-line-interface-cli&#34;&gt;
        #
    &lt;/a&gt;
    AWS Command Line Interface (CLI)
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;Another approach to accessing cloud storage is through the command line, to do this you must first download the AWS CLI on your computer. The following website will provide instructions on how you can download and get started with the AWS CLI depending on your operating system.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html&#34;&gt;https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The command line, when used correctly, can be a very powerful resource which allows users to run several software tools which do not have user interfaces. For the AWS CLI we typically start the program with the &lt;code&gt;aws&lt;/code&gt; command, when typed alone it will give you several options including a help page and the general format for a command. Here is an example of a aws command to list the contents of the JUMP-CP dataset, this command takes some time to run so don&amp;rsquo;t worry if it is slow.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws s3 ls --no-sign-request s3://cellpainting-gallery/
&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Explanation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(aws)&lt;/strong&gt; This invokes the aws program.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(s3)&lt;/strong&gt; Specifies that we want to access an s3 bucket.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(ls)&lt;/strong&gt; Linux command that allows us to list all of the files and folders in a directory&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(no-sign-request)&lt;/strong&gt; Is used when accessing public resources, skips authentication process&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(s3://directory/)&lt;/strong&gt; This is the directory/folder you wish to access&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;There are also more commands to work with the files and folders in s3 buckets including copying and moving data, these are almost identical to the previous command except we change the (ls) parameter to the appropriate Linux command. Below are some more examples&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Download File
aws s3 cp --no-sign-request s3://cellpainting-gallery/.../example.TIFF ./downloads/


# Download Folder
aws s3 cp --no-sign-request s3://cellpainting-gallery/.../example/ ./downloads/ --recursive


# Download Whole Bucket
aws s3 sync --no-sign-request s3://cellpainting-gallery/ ./downloads/
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;cloud-software-development-kits-sdks&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#cloud-software-development-kits-sdks&#34;&gt;
        #
    &lt;/a&gt;
    Cloud Software Development Kits (SDKs)
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;A more programmatic approach to access the cloud is through a Software Development Kit (SDK) i.e. a set of tools and libraries which can be used in application development. AWS  has their own SDK which can be loaded into a Python programming environment which allows users to download and upload data seamlessly while they are working with it. In this tutorial we will be using the AWS SDK which is called boto3. This approach will give us a lot more flexibility and will allow us to make very specific queries that we are interested in.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/SDK.jpeg&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;p&gt;The benefit to using a SDK like boto3 is that you can now access your cloud data within a cloud-based programming environment like Google Colab and keeping all of your work (code/analyses) on the cloud without having to download anything on your computer. It is not difficult to see why cloud computing is a major upgrade for a lot of people, especially those in the biological sciences who will be collaborating and sharing data/documents frequently.&lt;/p&gt;
&lt;h2 id=&#34;getting-started-with-boto3&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#getting-started-with-boto3&#34;&gt;
        #
    &lt;/a&gt;
    Getting Started With boto3
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;To download boto3 to your Google Colab notebook we will use the following command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install boto3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next you need to make the necessary libraries are loaded by entering the following three lines of code&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import boto3
from botocore import UNSIGNED
from botocore.config import Config
&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Explanation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Line 1 imports the main boto3 SDK and lines 2 and 3 import core (botocore) functionalities that allow us to access public cloud data without credentials/login information.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;For the first example you will learn how to use the boto3 SDK for basic tasks such as navigating the file hierarchy of the JUMP-CP data from project 1.&lt;/p&gt;
&lt;p&gt;In order to access the data folders from the colab we need to set up an s3 object so that we have access without an AWS account credentials. It is okay to copy-paste, but make sure to understand what is happening in the code.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ---------- PART 1 ---------- #

prefix = &#39;&#39; #e.g. &#39;cpg0016-jump/source_1/images/Batch1_20221004/images&#39;
s3 = boto3.client(&#39;s3&#39;, config=Config(signature_version=UNSIGNED))
paginator = s3.get_paginator(&#39;list_objects_v2&#39;)
pages = paginator.paginate(
    Bucket=&#39;cellpainting-gallery&#39;,
    Delimiter=&#39;/&#39;,
    Prefix=f&amp;quot;{prefix}/&amp;quot;)


# ---------- PART 2 ---------- #

folders = []
files = []

for page in pages:
    # Extract folders
    if &#39;CommonPrefixes&#39; in page:
        for k in page[&#39;CommonPrefixes&#39;]:
            folders.append(k[&#39;Prefix&#39;][:-1].replace(f&amp;quot;{prefix}/&amp;quot;, &amp;quot;&amp;quot;))

    # Extract files
    if &#39;Contents&#39; in page:
        for obj in page[&#39;Contents&#39;]:
            key = obj[&#39;Key&#39;]
            # Ensure it&#39;s not the directory itself
            if key != f&amp;quot;{prefix}/&amp;quot;:
                files.append(key.replace(f&amp;quot;{prefix}/&amp;quot;, &amp;quot;&amp;quot;))


# ---------- PART 3 ---------- #

print(&amp;quot;Folders:&amp;quot;, folders)
print(&amp;quot;Files:&amp;quot;, files)
&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Explanation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(Part 1)&lt;/strong&gt; The primary function of this code is load our dataset starting from a given &lt;code&gt;prefix&lt;/code&gt; and set up the necessary credentials for accessing the s3 bucket &lt;code&gt;cellpainting-gallery&lt;/code&gt;. The actual retrieval of the data within a directory is done by the paginator which splits large datasets into smaller pieces called pages.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(Part 2)&lt;/strong&gt; This code uses the list of pages we retrieved in part 1 and lists the contents of each page using a for-loop. Also note that we differentiate between files and folders and assign each item into the appropriate list for post-processing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(Part 3)&lt;/strong&gt; In this example part 3 of the code does not do much, here we print the names of all of the folders and files within the &lt;code&gt;prefix&lt;/code&gt; directory of the s3 bucket.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt;  Change the code above to display the contents of a directory of your choosing.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt;  Add some lines to the part 2 code to count the number of files and folders and then add some lines in part 3 print the counts.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note that in a more useful program you might do some additional post-processing on certain files or folders. For example, maybe you found out that the nuclei channel data for each image in a imaging dataset was defective for whatever reason, you could delete all of the files or fix them using another software simply by extracting the channel information from the file names and fixing all of them in a for loop. This would reduce the amount of manual labor to zero.&lt;/p&gt;
&lt;p&gt;Recall the microscope image naming convention &lt;code&gt;r01c01f01p01-ch1sk1fk1fl1.TIFF&lt;/code&gt;, we could automatically filter wells from the experiment or data associated with specific perturbations simply by using the file names and the AWS SDK. For example, typically we have a lookup table for drugs/perturbations and their associated plates and wells, this would allow for extremely efficient analyses workflows where we do not need all of the data.&lt;/p&gt;
&lt;h2 id=&#34;dissecting-filenames-in-python-using-regular-expressions&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#dissecting-filenames-in-python-using-regular-expressions&#34;&gt;
        #
    &lt;/a&gt;
    Dissecting Filenames in Python Using Regular Expressions
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;Regular expressions are a programming tool which is used to extract user-defined patterns within a piece of text (string). Here we can easily exploit the naming convention being of the form &lt;code&gt;[a-z]+\d+&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/rubular.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Explanation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(+)&lt;/strong&gt;      One or more occurrences&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;([a-z])&lt;/strong&gt;  Lowercase letter&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(\d)&lt;/strong&gt;     Numbers 0-9&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;Below is some Python code using the regular expression library to break down the image file names.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import re

filename = &amp;quot;r01c01f01p01-ch1sk1fk1fl1.TIFF&amp;quot;

# Remove the extension
base_name = filename.replace(&amp;quot;.TIFF&amp;quot;, &amp;quot;&amp;quot;)

# Split by &#39;-&#39;
parts = base_name.split(&amp;quot;-&amp;quot;)

# Extract individual parts
prefix_parts = re.findall(r&amp;quot;[a-z]+\d+&amp;quot;, parts[0])
suffix_parts = re.findall(r&amp;quot;[a-z]+\d+&amp;quot;, parts[1])

print(&amp;quot;Prefix parts:&amp;quot;, prefix_parts)  # [&#39;r01&#39;, &#39;c01&#39;, &#39;f01&#39;, &#39;p01&#39;]
print(&amp;quot;Suffix parts:&amp;quot;, suffix_parts)  # [&#39;ch1&#39;, &#39;sk1&#39;, &#39;fk1&#39;, &#39;fl1&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you’re interested in learning more about regular expressions and how they work, please refer to the additional reading at the end.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 3&lt;/strong&gt; Do some research online and determine a way to use the code I have provided to display the images corresponding to a specific well (in the form rXcY) of your choosing. Feel free to use AI tools if you are having a hard time.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;some-final-remarks&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#some-final-remarks&#34;&gt;
        #
    &lt;/a&gt;
    Some Final Remarks
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;To review, in this tutorial you learned how to access data in the cloud using two different methods (CLI and SDK). It should be noted that here we primarily dealt with AWS resources but the procedures for other cloud platforms are very similar, most have their own CLIs and SDKs. Aside from the cloud resources you have also learned how to parse file hierarchies and extract essential information from filenames using regular expressions. These skills will be useful for future tutorials and any projects you work on in the future beyond this class so it is important that you fully understand everything covered in this tutorial before moving on.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Looking Ahead&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the upcoming tutorials you will learn more about more software for morphological profiling cellular imaging data and continue working with the JUMP-CP data. Beyond morphological profiling we will move into more of the technicalities behind the image processing algorithms and how you can construct your own morphological profiler. Thanks for reading until the end, I hope you enjoyed this tutorial!&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Resources&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.geeksforgeeks.org/write-regular-expressions/&#34;&gt;Regular Expressions: GeeksforGeeks (Simple)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bakalian.cs.umd.edu/assets/notes/regex.pdf&#34;&gt;Regular Expressions: Cliff Bakalian (Intermediate)&lt;/a&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1] S. N. Chandrasekaran et al., “JUMP Cell Painting dataset: morphological impact of 136,000 chemical and genetic perturbations,” Mar. 2023, doi: &lt;a href=&#34;https://doi.org/10.1101/2023.03.23.534023&#34;&gt;https://doi.org/10.1101/2023.03.23.534023&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;[2] “Boto3 documentation — Boto3 Docs 1.16.56 documentation,” boto3.amazonaws.com. &lt;a href=&#34;https://boto3.amazonaws.com/v1/documentation/api/latest/index.html&#34;&gt;https://boto3.amazonaws.com/v1/documentation/api/latest/index.html&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>6. High-Throughput Cell Image Analysis With CellProfiler :dash:</title>
      <link>/posts/cellprofiler/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/cellprofiler/</guid>
      <description>&lt;p&gt;In this tutorial you will be introduced to the morphological profiling tool CellProfiler and some post-processing approaches.&lt;/p&gt;
&lt;h2 id=&#34;background&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#background&#34;&gt;
        #
    &lt;/a&gt;
    Background
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;There are many cases when we want to analyze thousands of cellular images such as when we do a large drug or CRISPR screen. Quantifying the effects that many drugs or gene perturbations has on cells can be challenging, this is why we use software such as Fiji. However, when we are screening thousands of drugs, we cannot analyze the resulting images manually as we did in project 1, it would take way too long. This is the same realization that Anne Carpenter had when she created the vision for CellProfiler.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/cell.jpeg&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;CellProfiler was first released by scientists at the Whitehead Institute for Biomedical Research in 2006,  it was originally written in the MATLAB programming language but was eventually re-implemented in Python. The main purpose of CellProfiler was to analyze image data from high-content screening and make thousands of measurements at the cellular level. The CellProfiler philosophy is ‘measure everything, ask questions later’ which can be very beneficial when working with lots of data. Much like Fiji, CellProfiler supports the Bio-Formats library as well as many of the same image adjustments. Additionally it supports more sophisticated classification using deep learning and provides dedicated preprocessing modules.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/pipeline.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;installation-and-setup&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#installation-and-setup&#34;&gt;
        #
    &lt;/a&gt;
    Installation and Setup
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;On Windows and Mac operating systems the CellProfiler is very simple, download the installer using the following link &lt;a href=&#34;https://cellprofiler.org/releases&#34;&gt;CellProfiler&lt;/a&gt; and install. If you’re on a device running Linux it’s going to be a little more involved using a Conda environment follow this link to learn more &lt;a href=&#34;https://github.com/CellProfiler/CellProfiler/wiki/Source-installation-(Linux)&#34;&gt;Linux Installation Instructions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once CellProfiler is up and running, you are first met with the a very plain user interface similar to Fiji. We will run through two examples using some of the default data, head over to the this link &lt;a href=&#34;https://cellprofiler.org/examples&#34;&gt;CellProfiler Example Data&lt;/a&gt; and download the files required for the fruit fly cells and the object tracking.&lt;/p&gt;
&lt;h2 id=&#34;examples&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#examples&#34;&gt;
        #
    &lt;/a&gt;
    Examples
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;We are now going to go over the two examples you just downloaded, after familiarizing yourself with simple functions and pipelines we will go into how you can make your own. Inside each example folder you will be met with two key pieces of information, first a CellProfiler pipeline file &lt;code&gt;.cppipe&lt;/code&gt; and then the data itself.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Setting Default Output&lt;/strong&gt;
When running pipelines you can automatically save all of the data from an analysis, when dealing with high throughput experiments this data can be become very large. To ensure you are saving all of your data in the correct place check &lt;code&gt;Output Settings&lt;/code&gt; on the bottom left and make sure that you select a convenient location to save all of the outputs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Automated Image Analysis Using Pipelines&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now that you have the set the output we are ready to analyze some imaging data. There are two primary steps when doing an analysis, loading the pipeline file and loading the data. Later we will go into more detail on how you can develop your own pipelines or where you can find more.&lt;/p&gt;
&lt;p&gt;Loading Pipeline: To load the pipeline into your workspace navigate to &lt;code&gt;File&lt;/code&gt; -&amp;gt; &lt;code&gt;Import Pipeline&lt;/code&gt; -&amp;gt; &lt;code&gt;From File&lt;/code&gt; and find the .cppipe file in the folder we downloaded.&lt;/p&gt;
&lt;p&gt;Loading Data: The pipeline will load all of the tasks or analyses we are doing on the images, not the images themselves. So now you want to import the images we will use for this analysis by dragging and dropping them in the main menu from the folder we downloaded earlier.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt; Now try it yourself, use the fruit fly pipeline and data we download earlier and run the analysis on CellProfiler&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt; Let’s do another example, this time with time-lapse data for object tracking.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;These two examples show how powerful CellProfiler is for analyzing many images at once. But as you may have noticed, it can take a while to run these pipelines. If you are interested in learning more about what exactly the measurements mean you can take a look at this resource &lt;a href=&#34;https://cellprofiler-manual.s3.amazonaws.com/CellProfiler-3.0.0/modules/measurement.html#measureobjectintensitydistribution&#34;&gt;From CellProfiler Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/measurements.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;If you don’t have the time to look at all of the measurements, here is a small preview using &lt;code&gt;MeasureObjectIntensityDistribution&lt;/code&gt;, the diagram above describes exactly what is being measured by this module. It is remarkable how CellProfiler can make this many measurements all at once. However, it also makes one think whether or not all of these measurements are necessary. We will speak on this problem in future tutorials.&lt;/p&gt;
&lt;h2 id=&#34;morphological-profiling-at-scale&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#morphological-profiling-at-scale&#34;&gt;
        #
    &lt;/a&gt;
    Morphological Profiling at Scale
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;Notice that unlike Fiji, we can’t really analyze a single image at our leisure, we must create a pipeline in order to analyze an image. For this reason CellProfiler is typically preferred when analyzing large datasets where we want to apply the same kind of analysis to all of our data. In cases where the dataset is small or we want to apply different kinds of analyses to individual images in a dataset, Fiji might be easier to use.&lt;/p&gt;
&lt;h3 id=&#34;pipeline-design&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#pipeline-design&#34;&gt;
        ##
    &lt;/a&gt;
    Pipeline Design
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;It is rare that the type of analysis we want to do on real lab data will be readily available online. For this reason many researchers working on imaging will develop their own CellProfiler pipelines to fit the specific study they are working on. &lt;a href=&#34;https://cellprofiler.org/published-pipelines&#34;&gt;Here&lt;/a&gt; is a neat resource, an official list of published pipelines that have been used in scientific studies in a diverse range of application areas. Unlike the examples from earlier, these downloads don’t come with the data from the study but it is still a useful in learning which modules are useful for which studies.&lt;/p&gt;
&lt;p&gt;Next we will familiarize ourselves with some of the classes of modules that are offered by CellProfiler.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;File Processing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;These modules are used either when you want to load data for usage or export data and save it to your files or a database.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Image Processing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The image processing modules are, for the most part, very similar to those found on the ImageJ/Fiji Image/Process tabs. Put simply, these are all modules that apply to an image as a whole. Upon adding one of these modules you will be met with additional options to including input, algorithm, output, and some miscellaneous file settings.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Object Processing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In CellProfiler we also have modules for individual objects within an image, this means that these apply to each object (cells, nuclei, organelles, etc.). These modules are used to do the actual identification/classification of objects or adjusting the size or attributes of those objects e.g. masking certain objects. To create objects, use the following functions&amp;hellip;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IdentifyPrimaryObjects&lt;/code&gt; Detects the smallest objects, such as nuclei.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IdentifySecondaryObjects&lt;/code&gt; Expands primary objects to identify regions like whole cells.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IdentifyTertiaryObjects&lt;/code&gt; Identifies regions by subtracting one object from another (e.g., cytoplasm = cell - nucleus).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/egg2.jpg&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Measurement&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;These modules will take measurements of your objects, this is very similar to the &lt;code&gt;Analyze&lt;/code&gt; tab in ImageJ/Fiji. If you remember the examples from earlier, the measurements that we made on the fruit fly cell images were very detailed. There are many options for the types of measurements being made, there are some that are taken in reference to the entire image and those which will correspond to individual objects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Tools&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The data tools in CellProfiler refer to any type of data visualization or computation of statistics both of which we also got to see in the examples. For the fruit fly example we had a bar graph displaying the various object information like counts and size.&lt;/p&gt;
&lt;h3 id=&#34;testing-and-debugging&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#testing-and-debugging&#34;&gt;
        ##
    &lt;/a&gt;
    Testing and Debugging
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;Before implementing your own pipeline it is important that you are aware of the &lt;code&gt;Test Mode&lt;/code&gt; offered by CellProfiler. This feature will be your best friend when developing pipelines as it is unlikely that you will get them to work perfectly the first time. The main function of the test mode is to run your pipeline on some test data and get a preview of the analysis results without saving everything. By using test mode you can tweak the module specifications ever so slightly and quickly see the effect on the result.&lt;/p&gt;
&lt;p&gt;If you have programmed before in languages such as Java, C, or C++ you may be familiar with the Java debugger (JDB) or GNU Debugger (GDB). These are powerful tools that allow you to run code line by line with the purpose of helping the programmer find the line where errors are arising. CellProfiler’s test mode will allow you to run your pipeline in a very similar way, i.e. instead of code we will run individual modules from the pipeline one by one to make sure we are getting a correct output at every stage. This was never a problem in Fiji as we are already running commands independently but when our objective becomes to create a long string of commands i.e. a pipeline then it becomes a little harder determine where problems are arising.&lt;/p&gt;
&lt;p&gt;CellProfiler’s test mode teaches us a very valuable lesson applicable to any type of program development, and that is how to break down your code to fix bugs. If you are ever stuck and your code is not running, the exact same approach should be taken.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 3&lt;/strong&gt; Implement a simple pipeline in CellProfiler to identify cell count, area, shape properties in the images you selected from project 1.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Looking Back&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Take a look at the input and output of a pipeline for the JUMP-CP data. Some of the pipeline files can be found &lt;a href=&#34;https://github.com/broadinstitute/imaging-platform-pipelines/tree/master/JUMP_production&#34;&gt;HERE&lt;/a&gt;, and another useful exercise is to go back to the JUMP-CP Quilt database found &lt;a href=&#34;https://open.quiltdata.com/b/cellpainting-gallery/tree/&#34;&gt;HERE&lt;/a&gt; and take a look around at the &lt;code&gt;Analysis&lt;/code&gt; folders, these folders contain the CellProfiler outputs for each and every image in the database. It is incredible to think about the scale and size of this database and how many CSV files there are in this AWS bucket. Manually analyzing these images without CellProfiler would be impossible so this would be a perfect example of when a software like this is game-changing.&lt;/p&gt;
&lt;p&gt;There are still many problems in cellular biology where there is no efficient computational workflow that exists for large datasets. This example shows the applicability and benefits of not only knowing how to use existing software but being able to engineer your own.&lt;/p&gt;
&lt;h2 id=&#34;post-processing&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#post-processing&#34;&gt;
        #
    &lt;/a&gt;
    Post-Processing
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;While there are a lot of tasks that CellProfiler can help on regarding morphological profiling tasks, it cannot analyze any of the profiling data or prepare the data for analysis. There is a category of tools that can help with this problem, we will go over one of these tools called Cytominer which serves the purpose of cleaning and preparing the data to make biological conclusions. The original version of Cytominer was implemented in R but now we have a Python adaptation called PyCytominer which is what we will use.&lt;/p&gt;
&lt;h3 id=&#34;more-on-the-cellprofiler-output&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#more-on-the-cellprofiler-output&#34;&gt;
        ##
    &lt;/a&gt;
    More On the CellProfiler Output
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;The CellProfiler output is a $n \times m$ matrix of values corresponding to a specific well on a plate from an experiment. Each of the $n$ rows of the matrix represent the cells found within the well, for each cell we also have $m$ features which can be used to describe those cells.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/matrix.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;p&gt;It is important to note that CellProfiler takes a lot of measurements, sometimes in the thousands. Measurements can be highly correlated meaning they depend on each other or can have significantly different distributions making comparison difficult. Having additional highly correlated features that do not contribute to the data that much can complicate further analysis of the results so we’d like to have a way to address these. These problems along with many others can be addressed using the PyCytominer Python package.&lt;/p&gt;
&lt;h3 id=&#34;pycytominer-features&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#pycytominer-features&#34;&gt;
        ##
    &lt;/a&gt;
    PyCytominer Features
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Aggregation&lt;/strong&gt;
As the name suggest, this module seeks to aggregate profiles and in particular several single-cell profiles into individual well profiles. This means that means that your new profile/matrix will have rows corresponding to wells as opposed to cells. The primary way to accomplish this is to use the mean or median. The function will summarize all of the cells corresponding to a well using one of these statistics, the default method is the median because it is less sensitive to outliers. Typically you would want to use this module when you have too much data and want to simplify the analysis. Do not use this if you are interested in single cell insights or outliers.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/aggregation.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Annotation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This module does not affect the data in any way but it instead helps incorporate the plate metadata into the profiles given a platemap. A platemap is a table that assigns each well in a plate an associated set of metadata values including experiment information, source, plate, etc.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Normalization&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When we say we want to normalize the data this typically means to get every feature on the same scale or have consistent distributions. This is useful because it allows us to analyze all of the measurements assuming they have the same range of values (helpful for many machine learning algorithms). Sometimes normalization can help remediate batch effect, the technical variation arising in data if it comes from several different experiments.&lt;/p&gt;
&lt;p&gt;From the source code we can see there are four different methods for normalization: avail_methods = &lt;code&gt;standardize&lt;/code&gt;, &lt;code&gt;robustize&lt;/code&gt;, &lt;code&gt;mad_robustize&lt;/code&gt;, &lt;code&gt;spherize&lt;/code&gt; It is not clear what these methods are doing based on the names or when they should be used. I will provide a short appendix at the end which will explain each one of these in a little more detail.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/normalization.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Feature Selection&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is the process of removing any non-informative features/measurements, this process is typically done using a variety of factors. The features that will be removed are those with low variance, are made up of almost all NaN values, are known to not be useful based on domain knowledge, any outliers, and features that are highly correlated with another. This procedure allows us to reduce the amount of data which greatly simplifies any type of analysis.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/features.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Consensus&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This module can be used when you have multiple replicates e.g. if you have multiple wells with the same perturbation/condition. The module will combine several replicate profiles corresponding to a user-provided label and create a consensus profile. The options here are either plate-level or well-level consensus using median values by default.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/consensus.png&#34; alt=&#34;Sunset&#34;&gt;&lt;/p&gt;
&lt;p&gt;Typically you would use a combination of these different modules to process your data before drawing any type of conclusions. There are more steps you could take in terms of post processing in order to make your data even more suitable but we will go over those in later tutorials. While it is common for PyCytominer to be used for data coming from large scale cell painting experiments, procedures such as feature selection and normalization are still widely used all kinds of machine learning tasks.&lt;/p&gt;
&lt;h2 id=&#34;final-remarks&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#final-remarks&#34;&gt;
        #
    &lt;/a&gt;
    Final Remarks
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;CellProfiler is a very powerful tool to do morphological profiling in cell imaging data. It is important to know when to use CellProfiler as opposed to other tools like Fiji/ImageJ so that you do not spend any extra effort. Additionally, post-processing is an important step in the analysis pipeline which is often overlooked, make sure to understand the PyCytominer package and when it should be used. Down below I have left some additional project ideas in order to familiarize yourself with these concepts further.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Additional Project Ideas&lt;/strong&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Project 1&lt;/strong&gt; Run cellprofiler on a subset of the JUMP-CP data using the JUMP-CP provided pipelines.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Project 2&lt;/strong&gt; Within the Quilt database for source 1 morphological profiles are provided for each and every well in their experiment, these come in the form of &lt;code&gt;.parquet&lt;/code&gt; files. Do some research on the file format and how to work with it, then use PyCytominer to process these into well-level profiles. Do this for about 10 wells.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Project 3 (Advanced)&lt;/strong&gt; Visualize the profiles from project 2 using different dimensionality reduction techniques such as different types of PCA, t-SNE, or UMAP. What do these plots represent? What does it mean if certain points are clustering, or are they all separate?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Resources&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cellprofiler-manual.s3.amazonaws.com/CellProfiler-4.2.8/index.html&#34;&gt;CellProfiler Documentation&lt;/a&gt;&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;



&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/KDQFUmDJ3nY&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1] D. R. Stirling, M. J. Swain-Bowden, A. M. Lucas, A. E. Carpenter, B. A. Cimini, and A. Goodman, “CellProfiler 4: improvements in speed, utility and usability,” BMC Bioinformatics, vol. 22, no. 1, Sep. 2021, doi: &lt;a href=&#34;https://doi.org/10.1186/s12859-021-04344-9&#34;&gt;https://doi.org/10.1186/s12859-021-04344-9&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;[2] E. Serrano et al., “Reproducible image-based profiling with Pycytominer,” &lt;a href=&#34;http://arxiv.org/&#34;&gt;arXiv.org&lt;/a&gt;, 2023. &lt;a href=&#34;https://arxiv.org/abs/2311.13417&#34;&gt;https://arxiv.org/abs/2311.13417&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;appendix-feature-normalization-techniques&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#appendix-feature-normalization-techniques&#34;&gt;
        #
    &lt;/a&gt;
    Appendix: Feature Normalization Techniques
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;For context the names of avail_methods are made up by the creators of PyCytominer. Here is a list of the normalization functions along with descriptions and cases when each of them should be used.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Standardize&lt;/strong&gt; - Z-Score Scaler&lt;/p&gt;
&lt;p&gt;$$
X_{scaled} = \frac{X-\mu}{\sigma}
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Robustize&lt;/strong&gt; - Robust normalization scaled by interquartile range&lt;/p&gt;
&lt;p&gt;$$
X_{scaled} = \frac{(X-median)}{IQR}
$$&lt;/p&gt;
&lt;p&gt;IQR is calculated as the difference between the 75th percentile (Q3) and the 25th percentile (Q1)&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Robustize MAD&lt;/strong&gt; - Robust normalization scaled by mean absolute deviation&lt;/p&gt;
&lt;p&gt;$$
MAD = \frac{1}{n}\sum_{i=1}^{n} |x_i-\mu|
$$&lt;/p&gt;
&lt;p&gt;$$
X_{scaled} = \frac{(X-median)}{MAD}
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt; These are called robust normalization techniques because they make use of robust statistics such as the median and mean absolute deviation. For a statistic to be robust means that it is less sensitive to outliers or non-Gaussian data, these are extreme values (very large or very small) that may influence the mean value. So now a good question is, when should robust normalization be used and, when it is used, when to scale by IQR vs MAD?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Spherize&lt;/strong&gt; - Sphering (Whitening) Transformation&lt;/p&gt;
&lt;p&gt;This method a bit different than all that were mentioned, it is a linear transformation that aims to decorrelate the features and normalize their variance to 1. If you have heard of principle component analysis (PCA) then this transformation may look a little familiar, the following description will require some knowledge of linear algebra but I will try my best to explain what is happening at each step.&lt;/p&gt;
&lt;p&gt;The following procedure is known as ZCA-Cor (Zero-Phase Component Analysis w.r.t Correlation) and is the default option in the PyCytominer Spherize method.&lt;/p&gt;
&lt;p&gt;Standardize Data: The first step is to make sure our data has mean zero for the covariance matrix computation. At the same time we can also ensure that our data has unit variance, this will suffice for the ZCA-Cor requirements.&lt;/p&gt;
&lt;p&gt;$$
X_{S} = \frac{X - \mu}{\sigma}
$$&lt;/p&gt;
&lt;p&gt;Covariance Matrix: The covariance matrix formula $\Sigma$ and its eigendecomposition.&lt;/p&gt;
&lt;p&gt;$$
\Sigma = \frac{1}{n-1} X_{S}^TX_{S}
$$&lt;/p&gt;
&lt;p&gt;$$
\Sigma = Q \Lambda Q^T
$$&lt;/p&gt;
&lt;p&gt;Compute Sphering Transform: We will take an alternative approach to compute the transform, this is the form for the PCA-Cor sphering transform. The Kessy et al. paper [3] tells us that the ZCA-Cor can be computed in the same way as PCA-Cor but simply adding an additional rotation to return to the original coordinates. To compute the sphering transform $W$ we can use the following&amp;hellip;&lt;/p&gt;
&lt;p&gt;$$
W = \Lambda^{-1/2}Q^{T}
$$&lt;/p&gt;
&lt;p&gt;First we will take the singular value decomposition (SVD) of our data $X_S$.&lt;/p&gt;
&lt;p&gt;$$
X_{S} = USV^{T}
$$&lt;/p&gt;
&lt;p&gt;Substituting the SVD in place of $X_S$.&lt;/p&gt;
&lt;p&gt;$$
\Sigma = \frac{1}{n-1} X_{S}^TX_{S} = \frac{1}{n-1} VSU^T USV^T =\frac{1}{n-1} VS^2V^T
$$&lt;/p&gt;
&lt;p&gt;This tells us that we can get the inverse square root of lambda from the following relationships&amp;hellip;&lt;/p&gt;
&lt;p&gt;$$
Q = V
$$&lt;/p&gt;
&lt;p&gt;$$
\Lambda = \frac{1}{n-1} S^2 \implies \Lambda^{-1/2} = S^{-1} \sqrt{n-1}
$$&lt;/p&gt;
&lt;p&gt;We now have the PCA-Cor sphering transform within the parenthesis and then an additional rotation $V$ to get the ZCA-Cor sphering transform.&lt;/p&gt;
&lt;p&gt;$$
W = V(S^{-1}V^T\sqrt{n-1})
$$&lt;/p&gt;
&lt;p&gt;Finally we can apply the transformation to our data.&lt;/p&gt;
&lt;p&gt;$$
Z = WX_{S}
$$&lt;/p&gt;
&lt;p&gt;Overall the sphering approach to normalization is a lot more involved than all of the others, but why should we bother? Sphering can be very useful depending on what kind of analysis you are doing, for example machine learning algorithms which use gradient-based optimization can benefit greatly from what it has to offer. Another reason why you might want to use sphering is because it can help with batch effect when combining several datasets from different experiments. We will go into greater depth on batch correction in the future. If you’re unsure of which normalization approach to use, you should experiment with different methods until you find the best for your use case.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;If you have any additional questions about the procedure discussed above please refer to the Kessy et al. paper [3] or the PyCytominer source code both referenced below.&lt;/p&gt;
&lt;div style=&#34;height: 20px;&#34;&gt;&lt;/div&gt;


&lt;p&gt;&lt;a href=&#34;https://github.com/cytomining/pycytominer&#34;&gt;Source Code&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] A. Kessy, A. Lewin, and K. Strimmer, “Optimal Whitening and Decorrelation,” The American Statistician, vol. 72, no. 4, pp. 309–314, Jan. 2018, doi: &lt;a href=&#34;https://doi.org/10.1080/00031305.2016.1277159&#34;&gt;https://doi.org/10.1080/00031305.2016.1277159&lt;/a&gt;.
‌&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
